# Production Docker Compose Configuration
# =========================================
# This file is optimized for production deployment.
# 
# Usage:
#   docker-compose -f docker-compose.prod.yml up -d
#
# Important Notes:
# - Secrets should be managed via Docker Secrets or external vault
# - Database should ideally be external (managed service)
# - Add reverse proxy (nginx/traefik) for SSL termination
# - Configure log aggregation (e.g., ELK stack)
# - Set up monitoring and alerting

services:
  # =========================================
  # PostgreSQL Database
  # =========================================
  # Note: In production, consider using a managed database service
  # (AWS RDS, Google Cloud SQL, Azure Database, etc.)
  db:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      # Performance tuning
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=en_US.UTF-8"
    volumes:
      - pgdata:/var/lib/postgresql/data
    # Optional: custom PostgreSQL configuration
    # - ./postgres.conf:/etc/postgresql/postgresql.conf:ro
    ports:
      # For production, don't expose this port or use firewall rules
      - "127.0.0.1:${POSTGRES_PORT:-5432}:5432"
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    # Security options
    security_opt:
      - no-new-privileges:true
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # =========================================
  # API User Service
  # =========================================
  api-user:
    build:
      context: .
      dockerfile: apps/api-user/Dockerfile
      target: prod
      args:
        NODE_ENV: production
    image: ${DOCKER_REGISTRY:-}modular-lms-api-user:${IMAGE_TAG:-latest}
    restart: unless-stopped
    env_file:
      - .env.production
    environment:
      NODE_ENV: production
      POSTGRES_HOST: db
      PORT: 3000
    depends_on:
      db:
        condition: service_healthy
    ports:
      - "${USER_API_PORT:-3001}:3000"
    networks:
      - backend
      - frontend
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      # Deployment strategy
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    # Security options
    security_opt:
      - no-new-privileges:true
    read_only: false
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # =========================================
  # API Admin Service
  # =========================================
  api-admin:
    build:
      context: .
      dockerfile: apps/api-admin/Dockerfile
      target: prod
      args:
        NODE_ENV: production
    image: ${DOCKER_REGISTRY:-}modular-lms-api-admin:${IMAGE_TAG:-latest}
    restart: unless-stopped
    env_file:
      - .env.production
    environment:
      NODE_ENV: production
      POSTGRES_HOST: db
      PORT: 3000
    depends_on:
      db:
        condition: service_healthy
    ports:
      - "${ADMIN_API_PORT:-3000}:3000"
    networks:
      - backend
      - frontend
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      # Deployment strategy
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    # Security options
    security_opt:
      - no-new-privileges:true
    read_only: false
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

# =========================================
# Optional: Nginx Reverse Proxy
# =========================================
# Uncomment if you want to use nginx for SSL termination
# nginx:
#   image: nginx:alpine
#   restart: unless-stopped
#   ports:
#     - "80:80"
#     - "443:443"
#   volumes:
#     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
#     - ./nginx/ssl:/etc/nginx/ssl:ro
#   depends_on:
#     - api-user
#     - api-admin
#   networks:
#     - frontend
#   healthcheck:
#     test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
#     interval: 30s
#     timeout: 10s
#     retries: 3

# =========================================
# Networks
# =========================================
networks:
  backend:
    driver: bridge
    internal: true  # Backend network is isolated
  frontend:
    driver: bridge

# =========================================
# Volumes
# =========================================
volumes:
  pgdata:
    driver: local
    # For production, consider using a named volume with backup strategy
    # or external volume management
